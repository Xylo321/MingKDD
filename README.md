# MingKDD

抓取一些我网站需要的数据做一个词典。

## 一、技术的难点

国外有一个requests库和lxml库，可以搞定一部分的没有反爬的数据，然后selenium和
google driver能搞定大部分的无头浏览器也反爬的网站，appium可以搞定手机app的爬取，
目前摆在爬虫面前的难题也就，验证码反爬，无头浏览器的反爬，其它的比如IP只需要有足够
的钱去买一些IP就可以了。

爬虫有时候，还需要针对目标站点的反爬策略，不断的更新自己，比如说，IP地址要不停的换，
目标更新了验证码的生成方式和校验方式，那么爬虫编写者又要去琢磨目标的验证码的生成原理
和程序自动化的方案，又比如，目标对google driver进行了识别，这样就需要去修改google
driver发送到目标的请求参数，将自己是无头浏览器这一参数个去掉。

爬虫与反爬最多也就这么几样，不会有太大的变化，无非就是爬虫和反爬者需要不断的更新策略，
爬虫需要拿到数据，反爬要让爬虫拿不到数据，双方需要不断的调整自己的状态，就像打仗一样，
谁要是退缩下来，或者，败下阵来，谁就输了。

所以，爬虫与反爬是一个非常累的工作。知乎上有评论说，经常因为这些搞爬虫的加班加到吐血。

## 二、抓取的站点

网址 | 网站名 | 网站类型 | 目标数据
:: | :: | :: | :: 
https://www.csdn.com | CSDN | 博客 | 文章
https://www.yingwang.org | 当然我在扯淡 | 博客 | 文章
https://www.runyifeng.com | 阮一峰的网络日志 | 博客 | 文章
https://hanjutv.com | 韩剧TV | 视频网站 | 韩剧视频